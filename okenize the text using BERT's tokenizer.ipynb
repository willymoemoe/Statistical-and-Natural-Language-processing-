{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30fe9d74-61c9-4900-a99b-8ebfeea84dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 18.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.8 MB 19.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.14.0-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 19.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2022.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/c91183a3-2950-452f-877d-df9c01a8c533/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/c91183a3-2950-452f-877d-df9c01a8c533/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed huggingface-hub-0.14.0 tokenizers-0.13.3 transformers-4.28.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d45e7-6c61-4ab3-bed6-34139d1e6526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (1.21.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.9/site-packages (4.28.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[K     |████████████████▏               | 312.8 MB 126.4 MB/s eta 0:00:03    | 212.2 MB 110.7 MB/s eta 0:00:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |███████████████████████████████▉| 615.9 MB 46.5 MB/s eta 0:00:011█████████████▌| 610.2 MB 46.5 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 619.9 MB 2.0 kB/s \n",
      "\u001b[?25hCollecting sklearn\n",
      "  Downloading sklearn-0.0.post4.tar.gz (3.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.local/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in ./.local/lib/python3.9/site-packages (from transformers) (0.14.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/anaconda-2022.05-py39/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8 MB 23.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[K     |████████████████████████████    | 278.2 MB 89.3 MB/s eta 0:00:01     |▊                               | 6.7 MB 24.1 MB/s eta 0:00:13     |███████████                     | 108.9 MB 97.9 MB/s eta 0:00:03     |███████████▍                    | 113.2 MB 97.9 MB/s eta 0:00:03/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas transformers torch sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2fa347-34ae-441c-b6ba-590f6f7a64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "\n",
    "# Load dataset (assuming CSV format with 'review_text', 'sentiment' columns)\n",
    "data = pd.read_csv('movie_reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f27e0f-f30e-477a-845b-bcdb640fec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the text using BERT's tokenizer:\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize(text):\n",
    "    return tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        add_special_tokens=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Tokenize the reviews\n",
    "data['tokens'] = data['review_text'].apply(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc36752-e91a-45a7-8972-298ad814cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing sets and create DataLoaders:\n",
    "X = data['tokens']\n",
    "y = data['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    torch.cat([item['input_ids'] for item in X_train.values], dim=0),\n",
    "    torch.cat([item['attention_mask'] for item in X_train.values], dim=0),\n",
    "    torch.tensor(y_train.values)\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.cat([item['input_ids'] for item in X_test.values], dim=0),\n",
    "    torch.cat([item['attention_mask'] for item in X_test.values], dim=0),\n",
    "    torch.tensor(y_test.values)\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=16)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a71149-37dd-467f-81e1-e7cb2de10bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#et up the BERT model, optimizer, and learning rate scheduler:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2022.05-py39",
   "language": "python",
   "name": "conda-env-anaconda-2022.05-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
